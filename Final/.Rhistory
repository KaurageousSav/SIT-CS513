hello <-"Hello World"
length(hello)
nchar(hello)
ls()
rm("x")
x2<-c(1,2,3,4)
?is.vector()  #### To determine if it is vector####
is.vector(hello)
mode(hello)
x2<-c(1,2,3)
x2
x1<-c(10,5,6,6,6,7)
x1
mode(x1)
x2<-c(1,2,3,4)
x2
x3<-x1+x2
x1
x2
x3
x1<-c(10,5,6,6,6,7)
x1
mode(x1)
x2<-c(1,2,3)
x2
x3<-x1+x2 ####Initially gave warning####
x1
x2
x3 ####Creates vector of the same size####
?seq()
x3<-seq(from=10.2,to=26.5,by=2.1)
x3<-seq(from=10.2,to=26.5,by=2.1)
mode(x3)
typeof(x3)
mean(x3)
x5<-seq(from=1,to=6,by=1)
typeof(x5)
x5<-seq(from=1,to=6,by=1)
typeof(x5)
print(x5)
x6<-1:6
typeof(x6)
print(x)
x6<-1:6
typeof(x6)
print(x6)
mixed_vector<-c(1,2,8.5,'5')
mode(mixed_vector)
typeof(mixed_vector)
typeof(mixed_vector)
intger_vector<-as.integer(mixed_vector)
typeof(intger_vector)
ls()
?rm()
rm(list=c("x3" ,"x5"))
objects<-ls()
rm(list=ls())
sample(100:200,50)
sample(150,97)
nrow(iris)
idx<-sample(nrow(iris),as.integer(.65*nrow(iris)))
idx
?sample
idx<-sample(nrow(iris),as.integer(.65*nrow(iris)))
training<-iris[idx,]
test<-iris[-idx,]
iris
attach(iris)
mmnorm <-function(x,minx,maxx)
{z<-((x-minx)/(maxx-minx))
return(z)
}
myvector<-1:20
mmnorm(myvector,1,20)
mmnorm2 <-function(x)
{z<-((x-min(x))/(max(x)-min(x)))
return(z)
}
myvector<-1:20
mmnorm2(myvector)
myvector<-1:20
mmnorm2(myvector)
myvector<-1:20
mmnorm(myvector,min(myvector),max(myvector))
f_print <-function(x1,x2,x3,x4,x5)
{
print(c('value of x1',x1))
print(c('value of x2',x2))
print(c('value of x3',x3))
print(c('value of x4',x4))
print(c('value of x5',x5))
}
f_print(10,5,3,2,1)
f_print(x2=10,x5<-5,4,3,2)
f_print <-function(x1,x2,x3,x4,x5)
{
print(c('value of x1',x1))
print(c('value of x2',x2))
print(c('value of x3',x3))
print(c('value of x4',x4))
print(c('value of x5',x5))
}
f_print
x<-c(1,2,6,6,6,6,7,7)
unique(x)
match(x, unique(x) )
install.packages("modeest")
?mlv()
library(modeest)
?mlv()
x_mfv<-mlv(x, method = "mfv", na.rm = TRUE,)
x_mfv
rm(list=ls())
data(iris)
data(iris)
View(iris)
length(iris)
nrow(iris)
iris_missing<-iris
iris_missing[c(3,30,40),3]<-NA
summary(iris_missing)
View(iris)
View(iris)
iris_missing<-iris
iris_missing[c(3,30,40),3]<-NA
View(iris)
?boxplot()
boxplot(iris[1:3])
?hist()
hist(iris$Sepal.Length)
?pairs()
pairs(iris[1:2] )
pairs(iris[1:4])
pairs(iris[1:4], main = "Iris Data ",      pch = 10 )
pairs(iris[1:4], main = "Anderson's Iris Data -- 3 species",
pch = 21, bg = c("red", "green3", "blue")[factor(iris$Species)])
mtext(c('Red=Sotosa','Blue=Virginica'), col=c("red","Blue"),side=1, line=c(3,4) )
iris_notmissing<-na.omit(iris_missing)
rm(list=ls())
?install.packages
install.packages("kknn")
installed.packages()
?kknn()
library(kknn)
?kknn()
data(iris)
View(iris)
idx<-sort(sample(nrow(iris),as.integer(.65*nrow(iris))))
training<-iris[idx,]
test<-iris[-idx,]
index <- seq(1,nrow(iris),by=5)
test<-iris[index,]
training <-iris[-index,]
?kknn()
predict_k5 <- kknn(formula=Species~., training, test[,-5], k=5,kernel ="rectangular")
predict_k5 <- kknn(formula=Species~., training, test[,-5], k=5,kernel ="rectangular")
fit <- fitted(predict_k5)
fit
table(Actual=test$Species,Fitted=fit)
mmnorm <-function(x,minx,maxx) {z<-((x-minx)/(maxx-minx))
return(z)
}
iris_normalized<-as.data.frame (
cbind( Sepal.Length=mmnorm(iris[,1],min(iris[,1]),max(iris[,1]))
, sepal.Width=mmnorm(iris[,2],min(iris[,2]),max(iris[,2] ))
,Petal.Length=mmnorm(iris[,3],min(iris[,3]),max(iris[,3] ))
, Petal.Width=mmnorm(iris[,4],min(iris[,4]),max(iris[,4] ))
,Species=as.character(iris[,5])
)
)
index <- seq(1,nrow(iris_normalized ),by=5)
test<-iris_normalized[index,]
training <-iris_normalized[-index,]
predict_k5 <- kknn(formula=Species~., training, test[,-5], k=5,kernel ="triangular" )
predict_k5 <- kknn(formula=Species~., training, test[,-5], k=5,kernel ="triangular" )
fit <- fitted(predict_k5)
table(Actual=test$Species,Fitted=fit)
rm(list=ls())
data(iris)
iris_missing<-iris
iris_missing[c(3,30,40),3]<-NA ##created missing values
summary(iris_missing)
iris_missing
library('VIM')
install.packages("VIM")
install.packages("VIM")
library('VIM')
iris_imput<-kNN(iris_missing,variable ='Petal.Length',k=3,
dist_var=c('Sepal.Length','Sepal.Width'))
iris_imput
rm(list=ls())
installed.packages()
library(e1071)
library(class)
install.packages("e1071")
install.packages("e1071")
csvfile<-file.choose()
Titanic_rows<-  read.csv(csvfile)
View(Titanic_rows)
summary(Titanic_rows)
class(Titanic_rows)
?prop.table
prop.table
table(class=Titanic_rows$Class,Survival=Titanic_rows$Survived)
prop.table(table(Class=Titanic_rows$Class,Survived=Titanic_rows$Survived))
nBayes_class <- naiveBayes(Survived ~Class, data =Titanic_rows)
category_class<-predict(nBayes_class,Titanic_rows  )
nBayes_class <- naiveBayes(Survived ~Class, data =Titanic_rows)
library(e1071)
library(class)
?naiveBayes()
nBayes_class <- naiveBayes(Survived ~Class, data =Titanic_rows)
category_class<-predict(nBayes_class,Titanic_rows  )
data_class<-cbind(Titanic_rows,category_class)
table(Class=Titanic_rows$Class,Survived=Titanic_rows$Survived)
table(Class=Titanic_rows$Class,NBayes=category_class)
table(NBayes=category_class,Survived=Titanic_rows$Survived)
nBayes_all <- naiveBayes(Survived ~., data =Titanic_rows)
nBayes_all
category_all<-predict(nBayes_all,Titanic_rows  )
table(NBayes_all=category_all,Survived=Titanic_rows$Survived)
NB_wrong<-sum(category_all!=Titanic_rows$Survived)
NB_wrong
length(category_all)
NB_error_rate<-NB_wrong/length(category_all) ##length gives no of items in vector
NB_error_rate
rm(list=ls())
installed.packages()
install.packages("rpart")
install.packages("rpart.plot")
install.packages("rattle")
install.packages("RColorBrewer")
library(rpart)
library(rpart.plot)
library(rattle)
library(RColorBrewer)
filename<-file.choose()
dsn<-  read.csv(filename )
dsn
library(rpart)
index<-sort(sample(nrow(dsn),round(.25*nrow(dsn))))
training<-dsn[-index,]
test<-dsn[index,]
dev.off()
CART_class<-rpart( Survived~.,data=training)
rpart.plot(CART_class)
CART_predict2<-predict(CART_class,test, type="class")
table(Actual=test[,4],CART=CART_predict2)
CART_predict<-predict(CART_class,test)
str(CART_predict)
CART_predict_cat<-ifelse(CART_predict[,1]<=.5,'Yes','No')
CART_predict
table(Actual=test[,4],CART=CART_predict_cat)
CART_wrong<-sum(test[,4]!=CART_predict_cat)
CART_error_rate<-CART_wrong/length(test[,4])
CART_error_rate
CART_predict2<-predict(CART_class,test, type="class")
CART_wrong2<-sum(test[,4]!=CART_predict2)
CART_error_rate2<-CART_wrong2/length(test[,4])
CART_error_rate2
library(rpart.plot)
prp(CART_class)
remove(list=ls())
filename<-file.choose()
Titanic<-  read.csv(filename)
Titanic2<-data.frame(lapply(na.omit(Titanic),as.numeric))
index<-sort(sample(nrow(Titanic2 ),round(.30*nrow( Titanic2))))
training<- Titanic2[-index,]
test<- Titanic2[index,]
index <- seq (1,nrow(Titanic2),by=5)
test<- Titanic2[index,]
training<-Titanic2[-index,]
install.packages("neuralnet")
library("neuralnet")
class(training$Survived)
net_Titanic2<- neuralnet( Survived~Class+Age+Sex ,training, hidden=10, threshold=0.01)
plot(net_Titanic2)
net_Titanic2<- neuralnet( Survived~Class+Age+Sex ,training, hidden=10, threshold=0.01)
rm(list=ls())
install.packages("neuralnet")
library("neuralnet")
#Importing csv to r
HW_07 <- read.csv("wisc_bc_ContinuousVar.csv", header = TRUE, na.strings = c("?"))
HW_07
rm(list=ls())
#Importing csv to r
Q1 <- read.csv("IBM_Attrition_v3.csv", header = TRUE, sep = ",", na.strings = c("?"))
View(Q1)
setwd("~/Desktop/SIT/kdd/Savleen/Final")
#Importing csv to r
Q1 <- read.csv("IBM_Attrition_v3.csv", header = TRUE, sep = ",", na.strings = c("?"))
View(Q1)
summary(Q1)
is.na(Q1)
#Remove Missing Values
Q1_withoutNA<-na.omit(Q1)
View(Q1_withoutNA)
Attrition_Modified <- data.frame(Q1_withoutNA)
Attrition_Modified
is.na(Attrition_Modified)
AgeLabel <- Attrition_Modified$Age
Attrition_Modified['AgeLabel'] <- AgeLabel
MonthlyIncomeLabel <- Attrition_Modified$MonthlyIncome
Attrition_Modified['MonthlyIncomeLabel'] <- MonthlyIncomeLabel
YearsAtCompanyLabel <- Attrition_Modified$YearsAtCompany
Attrition_Modified['YearsAtCompanyLabel'] <- YearsAtCompanyLabel
View(Attrition_Modified)
#categorizing MonthlyIncome
attach(Q1)
Attrition_Modified$MonthlyIncomeLabel[MonthlyIncomeLabel <= 2900 ] <- "Income 1"
Attrition_Modified$MonthlyIncomeLabel[MonthlyIncomeLabel > 2900 & MonthlyIncomeLabel <= 5000] <- "Income 2"
Attrition_Modified$MonthlyIncomeLabel[MonthlyIncomeLabel > 5000 & MonthlyIncomeLabel <= 8500] <- "Income 3"
Attrition_Modified$MonthlyIncomeLabel[MonthlyIncomeLabel > 8500] <- "Income 4"
detach(Attrition_Modified)
View(Attrition_Modified)
#categorizing YearsAtCompany
attach(Attrition_Modified)
Attrition_Modified$YearsAtCompanyLabel[YearsAtCompanyLabel <= 6] <- "Not-Senior"
Attrition_Modified$YearsAtCompanyLabel[YearsAtCompanyLabel > 6] <- "Senior"
detach(Attrition_Modified)
View(Attrition_Modified)
#categorizing Age
for(i in seq(from=1, to=nrow(Attrition_Modified), by=1))
{
if(Attrition_Modified$AgeLabel[i] < 38)
{
Attrition_Modified$AgeLabel [i] <- "young";
}
else if(Attrition_Modified$AgeLabel[i] > 37)
{
Attrition_Modified$AgeLabel[i] <- "mature";
}
}
View(Attrition_Modified)
Attrition_Modified <- Attrition_Modified[ -c(1,4:5) ]
View(Attrition_Modified)
rm(list=ls())
install.packages('randomForest')
setwd("~/Desktop/SIT/kdd/Savleen/Final")
Q2 <- read.csv("Attrition_Modified.csv", header = TRUE, sep = ",", na.strings = c("?"))
View(Q2)
Q2$Attrition<-factor(Q2$Attrition, labels = c("Yes","No"))
View(Q2$Attrition)
is.factor(Q2$Attrition)
#get same data
set.seed(111)
#test data & training data
idx<-seq(1,nrow(Q2),by=4)
idx
training<-Q2[-idx,]
nrow(training)
test<-Q2[idx,]
nrow(test)
library(randomForest)
fit <- randomForest( Attrition~., data=training, importance=TRUE, ntree=1000)
importance(fit)
varImpPlot(fit)
dev.off()
RPrediction <- predict(fit, test)
a<-table(actual=test$Attrition,RPrediction)
a
wrong<- (test$Attrition!=RPrediction )
error_rate<-sum(wrong)/length(wrong)
error_rate
#Accuracy
Accuracy <-(sum(diag(a))/(sum(rowSums(a)))*100)
Accuracy
training
test
rm(list=ls())
setwd("~/Desktop/SIT/kdd/Savleen/Final")
install.packages("C50")
Q3 <- read.csv("Attrition_Modified.csv", header = TRUE, sep = ",", na.strings = c("?"))
View(Q3)
#Convert Class Column to Factor
Q3$Attrition<-factor(Q3$Attrition, labels = c("Yes","No"))
View(Q3$Attrition)
is.factor(Q3$Attrition)
#get same data
set.seed(111)
#test data & training data
idx<-seq(1,nrow(Q3),by=4)
idx
training<-Q3[-idx,]
nrow(training)
test<-Q3[idx,]
nrow(test)
library('C50')
#C50
C50_class <- C5.0(Attrition~.,data=training )
summary(C50_class )
dev.off()
plot(C50_class)
C50_predict<-predict( C50_class ,test, type="class" )
str(C50_predict)
a<-table(actual=test$Attrition,C50=C50_predict)
a
#Accuracy
Accuracy <-(sum(diag(a))/(sum(rowSums(a)))*100)
Accuracy
#Error rate
e<-100-Accuracy
e
rm(list=ls())
Q1 <- read.csv("IBM_Attrition_v3.csv", header = TRUE, sep = ",", na.strings = c("?"))
View(Q1)
#I. Summarizing each column (e.g. min, max, mean )
summary(Q1)
is.na(Q1)
#Remove Missing Values
Q1_withoutNA<-na.omit(Q1)
View(Q1_withoutNA)
Attrition_Modified <- data.frame(Q1_withoutNA)
Attrition_Modified
is.na(Attrition_Modified)
AgeLabel <- Attrition_Modified$Age
Attrition_Modified['AgeLabel'] <- AgeLabel
MonthlyIncomeLabel <- Attrition_Modified$MonthlyIncome
Attrition_Modified['MonthlyIncomeLabel'] <- MonthlyIncomeLabel
YearsAtCompanyLabel <- Attrition_Modified$YearsAtCompany
Attrition_Modified['YearsAtCompanyLabel'] <- YearsAtCompanyLabel
View(Attrition_Modified)
#categorizing MonthlyIncome
attach(Q1)
Attrition_Modified$MonthlyIncomeLabel[MonthlyIncomeLabel <= 2900 ] <- "Income 1"
Attrition_Modified$MonthlyIncomeLabel[MonthlyIncomeLabel > 2900 & MonthlyIncomeLabel <= 5000] <- "Income 2"
Attrition_Modified$MonthlyIncomeLabel[MonthlyIncomeLabel > 5000 & MonthlyIncomeLabel <= 8500] <- "Income 3"
Attrition_Modified$MonthlyIncomeLabel[MonthlyIncomeLabel > 8500] <- "Income 4"
detach(Attrition_Modified)
View(Attrition_Modified)
#categorizing YearsAtCompany
attach(Attrition_Modified)
Attrition_Modified$YearsAtCompanyLabel[YearsAtCompanyLabel <= 6] <- "Not-Senior"
Attrition_Modified$YearsAtCompanyLabel[YearsAtCompanyLabel > 6] <- "Senior"
detach(Attrition_Modified)
View(Attrition_Modified)
#categorizing Age
for(i in seq(from=1, to=nrow(Attrition_Modified), by=1))
{
if(Attrition_Modified$AgeLabel[i] < 38)
{
Attrition_Modified$AgeLabel [i] <- "young";
}
else if(Attrition_Modified$AgeLabel[i] > 37)
{
Attrition_Modified$AgeLabel[i] <- "mature";
}
}
View(Attrition_Modified)
Attrition_Modified <- Attrition_Modified[ -c(1,4:5) ]
View(Attrition_Modified)
rm(list=ls())
install.packages('randomForest')
install.packages("randomForest")
Q2 <- read.csv("Attrition_Modified.csv", header = TRUE, sep = ",", na.strings = c("?"))
View(Q2)
Q2$Attrition<-factor(Q2$Attrition, labels = c("Yes","No"))
View(Q2$Attrition)
is.factor(Q2$Attrition)
#get same data
set.seed(111)
#test data & training data
idx<-seq(1,nrow(Q2),by=4)
idx
training<-Q2[-idx,]
nrow(training)
test<-Q2[idx,]
nrow(test)
library(randomForest)
fit <- randomForest( Attrition~., data=training, importance=TRUE, ntree=1000)
importance(fit)
varImpPlot(fit)
dev.off()
RPrediction <- predict(fit, test)
a<-table(actual=test$Attrition,RPrediction)
a
wrong<- (test$Attrition!=RPrediction )
error_rate<-sum(wrong)/length(wrong)
error_rate
#Accuracy
Accuracy <-(sum(diag(a))/(sum(rowSums(a)))*100)
Accuracy
rm(list=ls())
install.packages("C50")
Q3 <- read.csv("Attrition_Modified.csv", header = TRUE, sep = ",", na.strings = c("?"))
View(Q3)
#Convert Class Column to Factor
Q3$Attrition<-factor(Q3$Attrition, labels = c("Yes","No"))
View(Q3$Attrition)
is.factor(Q3$Attrition)
set.seed(111)
idx<-seq(1,nrow(Q3),by=4)
idx
training<-Q3[-idx,]
nrow(training)
test<-Q3[idx,]
nrow(test)
library('C50')
C50_class <- C5.0(Attrition~.,data=training )
summary(C50_class )
dev.off()
plot(C50_class)
C50_predict<-predict( C50_class ,test, type="class" )
str(C50_predict)
a<-table(actual=test$Attrition,C50=C50_predict)
a
#Accuracy
Accuracy <-(sum(diag(a))/(sum(rowSums(a)))*100)
Accuracy
#Error rate
e<-100-Accuracy
e
